{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5535dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "-  patient_role exhibit with symptom of cough and gruffness of breath .\n",
      "-  Physical scrutiny revealed elevated temperature and wheeze .\n",
      "-  Diagnosis confirmed American_Samoa bronchitis , prescribe antibiotics and inhaler .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to get synonyms of a word using NLTK WordNet\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "# Function to perform synonym replacement in a text\n",
    "def synonym_replacement(text, num_replacements=1):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    augmented_text = []\n",
    "    for word in words:\n",
    "        if random.random() < 0.5:  # Probability of replacing each word\n",
    "            synonyms = get_synonyms(word)\n",
    "            if synonyms:\n",
    "                replacement = random.choice(synonyms)\n",
    "                augmented_text.append(replacement)\n",
    "            else:\n",
    "                augmented_text.append(word)\n",
    "        else:\n",
    "            augmented_text.append(word)\n",
    "    return ' '.join(augmented_text)\n",
    "\n",
    "# Augmenting each medical transcript\n",
    "augmented_transcripts = [synonym_replacement(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcca2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath. additional_word\n",
      "-  Physical additional_word examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics additional_word and inhaler.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to perform random insertion in a text\n",
    "def random_insertion(text, num_insertions=1):\n",
    "    words = text.split()\n",
    "    for _ in range(num_insertions):\n",
    "        insertion_point = random.randint(0, len(words))\n",
    "        insertion_word = \"additional_word\"\n",
    "        words.insert(insertion_point, insertion_word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Augmenting each medical transcript\n",
    "augmented_transcripts = [random_insertion(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876001f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "-  Patient of of\n",
      "-  Physical examination temperature\n",
      "-  Diagnosis confirmed prescribed antibiotics and inhaler.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to perform random deletion in a text\n",
    "def random_deletion(text, probability=0.5):\n",
    "    words = text.split()\n",
    "    remaining_words = [word for word in words if random.random() > probability]\n",
    "    return ' '.join(remaining_words)\n",
    "\n",
    "# Augmenting each medical transcript\n",
    "augmented_transcripts = [random_deletion(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1f25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "-  Patient presented with symptoms of shortness and cough of breath.\n",
      "-  Physical examination revealed wheezing. temperature and elevated\n",
      "-  Diagnosis confirmed and bronchitis, prescribed antibiotics as inhaler.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to perform random swap in a text\n",
    "def random_swap(text, num_swaps=1):\n",
    "    words = text.split()\n",
    "    for _ in range(num_swaps):\n",
    "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Augmenting each medical transcript\n",
    "augmented_transcripts = [random_swap(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e61fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Error occurred: 'NoneType' object has no attribute 'group'\n",
      "Original Transcripts:\n",
      "1. Patient presented with symptoms of cough and shortness of breath.\n",
      "2. Physical examination revealed elevated temperature and wheezing.\n",
      "3. Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "1. Patient presented with symptoms of cough and shortness of breath.\n",
      "2. Physical examination revealed elevated temperature and wheezing.\n",
      "3. Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Initialize translator\n",
    "translator = Translator()\n",
    "\n",
    "# Function to perform back-translation\n",
    "def back_translate(text, src_lang='en', target_lang='fr'):\n",
    "    try:\n",
    "        # Translate to the target language\n",
    "        translated_text = translator.translate(text, src=src_lang, dest=target_lang).text\n",
    "        # Introduce artificial delay to avoid rate limiting\n",
    "        time.sleep(random.uniform(0.5, 1.5))\n",
    "        # Translate back to the source language\n",
    "        back_translated_text = translator.translate(translated_text, src=target_lang, dest=src_lang).text\n",
    "        return back_translated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Perform back-translation on each transcript with retry and exponential backoff\n",
    "augmented_transcripts = []\n",
    "for transcript in medical_transcripts:\n",
    "    retries = 3\n",
    "    for _ in range(retries):\n",
    "        translated_text = back_translate(transcript)\n",
    "        if translated_text is not None:\n",
    "            augmented_transcripts.append(translated_text)\n",
    "            break\n",
    "        else:\n",
    "            # Retry with exponential backoff\n",
    "            delay = 2 ** _  # Exponential backoff\n",
    "            time.sleep(delay)\n",
    "    else:\n",
    "        # If all retries fail, use original text\n",
    "        augmented_transcripts.append(transcript)\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for i, transcript in enumerate(medical_transcripts):\n",
    "    print(f\"{i+1}. {transcript}\")\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for i, transcript in enumerate(augmented_transcripts):\n",
    "    print(f\"{i+1}. {transcript}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00e1f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting googletrans==4.0.0-rc1\n",
      "  Using cached googletrans-4.0.0rc1-py3-none-any.whl\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2021.10.8)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\siva7\\appdata\\roaming\\python\\python39\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Installing collected packages: googletrans\n",
      "  Attempting uninstall: googletrans\n",
      "    Found existing installation: googletrans 3.0.0\n",
      "    Uninstalling googletrans-3.0.0:\n",
      "      Successfully uninstalled googletrans-3.0.0\n",
      "Successfully installed googletrans-4.0.0rc1\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a615be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "-  affected_role show with symptom of cough and abruptness of breathing_time .\n",
      "-  forcible testing bring_out noble-minded temperature and wheeze .\n",
      "-  diagnosing reassert deoxyadenosine_monophosphate bronchitis , prescribed antibiotic and inhalator .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to get synonyms of a word using NLTK WordNet\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "# Function to perform paraphrasing in a text\n",
    "def paraphrase(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    paraphrased_text = []\n",
    "    for word in words:\n",
    "        synonyms = get_synonyms(word)\n",
    "        if synonyms:\n",
    "            paraphrased_word = random.choice(synonyms)\n",
    "            paraphrased_text.append(paraphrased_word)\n",
    "        else:\n",
    "            paraphrased_text.append(word)\n",
    "    return ' '.join(paraphrased_text)\n",
    "\n",
    "# Augmenting each medical transcript\n",
    "augmented_transcripts = [paraphrase(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6601e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts:\n",
      "-  affected_role introduce with symptom of cough and brusqueness of breath .\n",
      "-  strong-arm scrutiny let_out kick_upstairs temperature and wheezy .\n",
      "-  diagnosis support Eastern_Samoa bronchitis , order antibiotic_drug and inhaler .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to get synonyms of a word using NLTK WordNet\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "# Function to perform paraphrasing in a text\n",
    "def paraphrase(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    paraphrased_text = []\n",
    "    for word in words:\n",
    "        synonyms = get_synonyms(word)\n",
    "        if synonyms:\n",
    "            paraphrased_word = random.choice(synonyms)\n",
    "            paraphrased_text.append(paraphrased_word)\n",
    "        else:\n",
    "            paraphrased_text.append(word)\n",
    "    return ' '.join(paraphrased_text)\n",
    "\n",
    "# Augmenting each medical transcript\n",
    "augmented_transcripts = [paraphrase(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f9bdb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Transcripts:\n",
      "1. of shortness and symptoms cough . breath with Patient presented of\n",
      "2. presented with symptoms Patient . breath shortness of and cough of\n",
      "3. breath presented of and of . symptoms cough Patient with shortness\n",
      "4. . wheezing temperature revealed Physical and examination elevated\n",
      "5. as . and bronchitis prescribed inhaler antibiotics confirmed Diagnosis ,\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "# Example medical transcripts data\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to generate new sentences based on existing ones\n",
    "def generate_text(sentences, num_sentences=5):\n",
    "    generated_sentences = []\n",
    "\n",
    "    for _ in range(num_sentences):\n",
    "        # Randomly select a sentence from the existing transcripts\n",
    "        random_sentence = random.choice(sentences)\n",
    "\n",
    "        # Tokenize the sentence into words\n",
    "        words = nltk.word_tokenize(random_sentence)\n",
    "\n",
    "        # Shuffle the words to create variations\n",
    "        random.shuffle(words)\n",
    "\n",
    "        # Join the shuffled words to form a new sentence\n",
    "        new_sentence = ' '.join(words)\n",
    "        generated_sentences.append(new_sentence)\n",
    "\n",
    "    return generated_sentences\n",
    "\n",
    "# Generate new medical transcripts\n",
    "generated_transcripts = generate_text(medical_transcripts)\n",
    "\n",
    "# Print the generated transcripts\n",
    "print(\"Generated Transcripts:\")\n",
    "for i, transcript in enumerate(generated_transcripts, 1):\n",
    "    print(f\"{i}. {transcript}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "792ca2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.1% 19.0/1662.8MB downloaded"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load pre-trained word embeddings (word2vec)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m word_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword2vec-google-news-300\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sample medical transcripts\u001b[39;00m\n\u001b[0;32m      8\u001b[0m medical_transcripts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient presented with symptoms of cough and shortness of breath.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhysical examination revealed elevated temperature and wheezing.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\downloader.py:496\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    494\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_dir, file_name)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder_dir):\n\u001b[1;32m--> 496\u001b[0m     \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_path:\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\downloader.py:396\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    394\u001b[0m fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{fname}\u001b[39;00m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    395\u001b[0m dst_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp_dir, fname)\n\u001b[1;32m--> 396\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _calculate_md5_checksum(dst_path) \u001b[38;5;241m==\u001b[39m _get_checksum(name):\n\u001b[0;32m    398\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained word embeddings (word2vec)\n",
    "word_vectors = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to perform word embedding interpolation\n",
    "def word_embedding_interpolation(text, alpha=0.5):\n",
    "    words = text.split()\n",
    "    interpolated_text = []\n",
    "\n",
    "    # Iterate through each word in the text\n",
    "    for word in words:\n",
    "        # Check if word exists in the word embeddings vocabulary\n",
    "        if word in word_vectors:\n",
    "            # Get word embeddings\n",
    "            word_vector = word_vectors[word]\n",
    "\n",
    "            # Generate a random vector for interpolation\n",
    "            random_vector = np.random.rand(len(word_vector))\n",
    "\n",
    "            # Interpolate between word vector and random vector\n",
    "            interpolated_vector = (1 - alpha) * word_vector + alpha * random_vector\n",
    "\n",
    "            # Find the closest word in the embeddings space to the interpolated vector\n",
    "            closest_word = word_vectors.similar_by_vector(interpolated_vector)[0][0]\n",
    "            interpolated_text.append(closest_word)\n",
    "        else:\n",
    "            interpolated_text.append(word)\n",
    "\n",
    "    return ' '.join(interpolated_text)\n",
    "\n",
    "# Augmenting each medical transcript with word embedding interpolation\n",
    "augmented_transcripts = [word_embedding_interpolation(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts with Word Embedding Interpolation:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37269be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts with Text Rotation Interpolation:\n",
      "-  cough and shortness of breath. Patient presented with symptoms of\n",
      "-  temperature and wheezing. Physical examination revealed elevated\n",
      "-  prescribed antibiotics and inhaler. Diagnosis confirmed as bronchitis,\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to perform text rotation interpolation\n",
    "def text_rotation_interpolation(text, rotation_factor=0.5):\n",
    "    words = text.split()\n",
    "    num_rotations = round(len(words) * rotation_factor)\n",
    "    rotated_text = words[num_rotations:] + words[:num_rotations]\n",
    "    return ' '.join(rotated_text)\n",
    "\n",
    "# Augmenting each medical transcript with text rotation interpolation\n",
    "augmented_transcripts = [text_rotation_interpolation(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts with Text Rotation Interpolation:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac2d670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Transcripts:\n",
      "-  Patient presented with symptoms of cough and shortness of breath.\n",
      "-  Physical examination revealed elevated temperature and wheezing.\n",
      "-  Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\n",
      "\n",
      "Augmented Transcripts with Text Masking Interpolation:\n",
      "-  Patient MASK MASK symptoms MASK MASK and shortness of MASK\n",
      "-  Physical MASK revealed elevated MASK MASK MASK\n",
      "-  Diagnosis MASK MASK MASK prescribed antibiotics and MASK\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample medical transcripts\n",
    "medical_transcripts = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Function to perform text masking interpolation\n",
    "def text_masking_interpolation(text, masking_factor=0.5):\n",
    "    words = text.split()\n",
    "    num_words_to_mask = round(len(words) * masking_factor)\n",
    "    masked_indices = random.sample(range(len(words)), num_words_to_mask)\n",
    "    masked_text = [word if idx not in masked_indices else 'MASK' for idx, word in enumerate(words)]\n",
    "    return ' '.join(masked_text)\n",
    "\n",
    "# Augmenting each medical transcript with text masking interpolation\n",
    "augmented_transcripts = [text_masking_interpolation(transcript) for transcript in medical_transcripts]\n",
    "\n",
    "# Print original and augmented transcripts\n",
    "print(\"Original Transcripts:\")\n",
    "for transcript in medical_transcripts:\n",
    "    print(\"- \", transcript)\n",
    "\n",
    "print(\"\\nAugmented Transcripts with Text Masking Interpolation:\")\n",
    "for augmented_transcript in augmented_transcripts:\n",
    "    print(\"- \", augmented_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482472c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
